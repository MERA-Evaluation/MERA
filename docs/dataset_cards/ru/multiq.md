# MultiQ

## Описание задачи

**MultiQ** - это вопросно-ответный multi-hop датасет для русского языка. Датасет основан на одноименном [датасете](https://tape-benchmark.com/datasets.html#multiq) из бенчмарка TAPE.

Ключевые слова: multi-hop QA, вопросно-ответное задание, знания о мире, логика

**Авторы:** Екатерина Такташева, Татьяна Шаврина, Алена Феногенова, Денис Шавелев, Надежда Катричева, Мария Тихонова, Альбина Ахметгареева, Олег Зинкевич, Анастасия Башмакова, Светлана Иорданская, Алена Спиридонова, Валентина Курешникова, Екатерина Артемова, Владислав Михайлов

## Мотивация

В диагностическом задании мы стремимся ответить на следующий вопрос: могут ли большие языковые модели эффективно перефразировать токсичную и оскорбительную лексику вежливыми альтернативами, сохраняя при этом первоначальный смысл и качество текста? В этом задании оценивается способность модели распознавать и преобразовывать токсичные предложения в более вежливые, что требует глубокого понимания языковых нюансов и умения создавать альтернативные выражения без изменения предполагаемого сообщения. По сути, мы стремимся оценить, насколько хорошо языковые модели могут нормализовывать и улучшать текст для более уважительного общения.

Вопросно-ответные системы всегда играли важную роль в задачах обработки естественного языка. Однако некоторые области , связанные с вопросно-ответными заданиями, все еще являются достаточно сложными для современных моделей. К таким задачам относятся в том числе вопросно-ответные multi-hop задачи. такие как MultiQ.

## Описание датасета

### Поля данных

- meta — словарь, содержащий метаинформацию о примере:
    - id — номер примера в датасете;
    - bridge_answer — список сущностей, необходимых для того чтобы с использованием двух имеющихся текстов дать по ним ответ на вопрос, содержащийся в поле outputs;
- instruction — строка содержащая инструкции для задания;
- inputs — словарь, содержащий следующую информацию:
    - text — строка с основным текстом;
    - support_text — строка с дополнительным текстом;
    - question — вопрос, ответ на который содержится в данных текстах;
- outputs — строка, содержащая правильный ответ.

### Примеры данных

Каждый пример состоит из двух текстов (основного и дополнительного), а также вопроса по этим текстам, на который необходимо дать правильный ответ.

```json
{
    "instruction": "Даны два текста:\nТекст 1: {support_text}\nТекст 2: {text}\nОпираясь на данные тексты, ответьте на вопрос: {question}\nВаш ответ не должен содержать дополнительные объяснения.\nОтвет:",
    "inputs": {
        "text": "Нижний Новгород (в разговорной речи часто — \"Нижний\", c XIII по XVII век — Новгород Низовской земли, с 7 октября 1932 по 22 октября 1990 года — Горький) — город в центральной России, административный центр Приволжского федерального округа и Нижегородской области. Второй по численности населения город в Приволжском федеральном округе и на реке Волге.\\n\\nКультура.\\nИсторический центр Нижнего Новгорода, расположенный в Нагорной части города, несмотря на значительные перестройки, сохранил значительное число исторических гражданских строений XVIII — начала XX веков, включая многочисленные памятники деревянного зодчества. Дмитриевская башня Кремля выходит на историческую площадь Минина и Пожарского. Нижегородский кремль является официальной резиденцией Городской думы Нижнего Новгорода и правительства Нижегородской области. Зоопарк \"Лимпопо\". Зоопарк \"Лимпопо\" — первый частный зоопарк в России, расположенный в Московском районе.",
        "support_text": "Евгений Владимирович Крестьянинов (род. 12 июля 1948, Горький) — российский государственный деятель.",
        "question": "Как называется законодательный орган города, где родился Евгений Владимирович Крестьянинов?"
    },
    "outputs": "Городской думы",
    "meta": {
        "id": 0,
        "bridge_answers": "Горький"
    }
}
```

### Разбиение данных

Датасет состоит из 1056 обучающих примеров (train set) и 900 тестовых примеров (test set).

### Промпты

Для датасета было подготовлено 10 промптов различной сложности.

Пример:

```json
"Текст 1: {support_text}\nТекст 2: {text}\nОпираясь на данные тексты, ответьте на вопрос: {question}\nЗапишите только ответ без дополнительных объяснений.\nОтвет:"
```

### Создание датасета

Датасет основан на соответствующем датасете из бенчмарка TAPE [1], и был собран из текстов Википедии и WikiData. Полное описание сбора данных можно найти [по ссылке](https://tape-benchmark.com/datasets.html#multiq).

## Оценка

### Метрики

Для оценки моделей на данном датасете используются две метрики: F1 score и полное совпадение (Exact Match - EM).

### Человеческая оценка

Результаты F1 score /EM равны **0**.**92 / 0.91**, соответственно.

## Литература

[1] Taktasheva, Ekaterina, et al. "TAPE: Assessing Few-shot Russian Language Understanding." *Findings of the Association for Computational Linguistics: EMNLP 2022*. 2022.
