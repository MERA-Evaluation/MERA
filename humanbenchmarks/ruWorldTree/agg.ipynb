{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Аггрегация разметки датасета ruWorldTree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Аггрегация строится по следующей системе:\n",
    "\n",
    "1. Сбор размеченных пулов с Толоки. Возможны варианты:\n",
    "    - только общий пул нужно аггрегировать, тогда забирается только он\n",
    "    - часть данных находится в контрольных заданиях и экзамене, тогда к основному пулу добавляются данные задания\n",
    "2. Фильтрация разметчиков:\n",
    "    - в общем пуле есть некоторое количество заранее размеченных заданий - контрольных\n",
    "    - хорошим считается разметчик, который показывает `accuracy >= 0.5` на данных заданиях\n",
    "    - формируется список \"плохих\" разметчиков\n",
    "3. Аггрегация ответов разметчиков по заданиям:\n",
    "    - форматирование в заданиях может отличаться от изначального из-за выгрузки с Толоки\n",
    "    - учитываются только ответы \"хороших\" разметчиков\n",
    "    - аггрегация по подготовленным пулам - создается массив карточек вида {key: value}, где key - кортеж из всех значимых элементов задания, value - список из кортежей вида (user_id, answer)\n",
    "4. Голосование большинством по каждому заданию:\n",
    "    - минимально необходимое большинство составляет 3 голоса, так как такое большинство валидно для перекрытия 5\n",
    "    - по результату формируется датафрейм с заданиями и ответами\n",
    "5. Подгрузка оригинальных данных с разметкой в виде таблицы с заданиями и ответами\n",
    "6. Соединение таблиц:\n",
    "    - очистка форматирования в таблице с ответами разметчиков и в таблице с правильными ответами\n",
    "    - создание единых столбцов с полным заданием\n",
    "    - соединение таблиц по данному столбцу\n",
    "    - валидация размеров\n",
    "7. Подсчет метрик"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Сбор данных разметки и фильтрация разметчиков"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Датасет для разметки состоит из 525 объектов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "assignments = pd.read_csv('assignments_from_pool_42366885__28-11-2023.tsv', sep='\\t')\n",
    "skills = pd.read_csv('workerSkills.csv', sep='|')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разметчикам предлагалось на основании контекста из решенных пяти примеров и одного нерешенного примера ответить на вопрос, чему равен нерешенный пример, если заменить в нем специальный символ `->` соответственно контексту.\n",
    "Вход: \n",
    "- INPUT:question (пример: `Правда, что Солнце вращается вокруг Земли?`).\n",
    "- INPUT:option_a (пример: `Правда`).\n",
    "- INPUT:option_b (пример: `Неправда`).\n",
    "- INPUT:option_c (пример: `Недоказуемо`).\n",
    "- INPUT:option_d (пример: `Суждение логически противоречиво`).\n",
    "\n",
    "Выход:\n",
    "- OUTPUT:answer (одна из четырех букв: `A`, `B`, `C`, `D`,)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>INPUT:option_a</th>\n",
       "      <th>INPUT:option_b</th>\n",
       "      <th>INPUT:option_c</th>\n",
       "      <th>INPUT:option_d</th>\n",
       "      <th>INPUT:question</th>\n",
       "      <th>OUTPUT:answer</th>\n",
       "      <th>GOLDEN:answer</th>\n",
       "      <th>HINT:text</th>\n",
       "      <th>HINT:default_language</th>\n",
       "      <th>ASSIGNMENT:link</th>\n",
       "      <th>ASSIGNMENT:task_id</th>\n",
       "      <th>ASSIGNMENT:assignment_id</th>\n",
       "      <th>ASSIGNMENT:task_suite_id</th>\n",
       "      <th>ASSIGNMENT:worker_id</th>\n",
       "      <th>ASSIGNMENT:status</th>\n",
       "      <th>ASSIGNMENT:started</th>\n",
       "      <th>ASSIGNMENT:submitted</th>\n",
       "      <th>ASSIGNMENT:accepted</th>\n",
       "      <th>ASSIGNMENT:reward</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Дождь</td>\n",
       "      <td>Лед</td>\n",
       "      <td>Мороз</td>\n",
       "      <td>Пар</td>\n",
       "      <td>Что из этого является примером жидкой воды?</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://platform.toloka.ai/task/42366885/00028...</td>\n",
       "      <td>00028677a5--656635d172d52b5a0213fee2</td>\n",
       "      <td>00028677a5--65663c5aedc5b13fcc9bec79</td>\n",
       "      <td>00028677a5--65663c59edc5b13fcc9bec77</td>\n",
       "      <td>6853949dd8cb10f36cf4cade63a12f82</td>\n",
       "      <td>APPROVED</td>\n",
       "      <td>2023-11-28T19:15:38.042</td>\n",
       "      <td>2023-11-28T19:16:13.892</td>\n",
       "      <td>2023-11-28T19:16:13.892</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  INPUT:option_a INPUT:option_b INPUT:option_c INPUT:option_d  \\\n",
       "0          Дождь            Лед          Мороз            Пар   \n",
       "\n",
       "                                INPUT:question OUTPUT:answer GOLDEN:answer  \\\n",
       "0  Что из этого является примером жидкой воды?             A             A   \n",
       "\n",
       "   HINT:text  HINT:default_language  \\\n",
       "0        NaN                    NaN   \n",
       "\n",
       "                                     ASSIGNMENT:link  \\\n",
       "0  https://platform.toloka.ai/task/42366885/00028...   \n",
       "\n",
       "                     ASSIGNMENT:task_id              ASSIGNMENT:assignment_id  \\\n",
       "0  00028677a5--656635d172d52b5a0213fee2  00028677a5--65663c5aedc5b13fcc9bec79   \n",
       "\n",
       "               ASSIGNMENT:task_suite_id              ASSIGNMENT:worker_id  \\\n",
       "0  00028677a5--65663c59edc5b13fcc9bec77  6853949dd8cb10f36cf4cade63a12f82   \n",
       "\n",
       "  ASSIGNMENT:status       ASSIGNMENT:started     ASSIGNMENT:submitted  \\\n",
       "0          APPROVED  2023-11-28T19:15:38.042  2023-11-28T19:16:13.892   \n",
       "\n",
       "       ASSIGNMENT:accepted  ASSIGNMENT:reward  \n",
       "0  2023-11-28T19:16:13.892               0.03  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assignments.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Фильтруем толокеров с `accuracy < 0.5` на контрольных заданиях, чтобы не учитывать их ответы при подсчете метрик."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Users total:  191\n",
      "Bad users: 41\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "users_dict = defaultdict(lambda: defaultdict(int))\n",
    "\n",
    "for idx, row in assignments.iterrows():\n",
    "    question = row[4]\n",
    "\n",
    "    out = row[5]\n",
    "    \n",
    "    gold = row[6]\n",
    "\n",
    "    user = row[13]\n",
    "\n",
    "    if str(user) != \"nan\" and str(gold) != \"nan\":\n",
    "        if out == gold:\n",
    "            users_dict[user][\"good\"] += 1\n",
    "        else:\n",
    "            users_dict[user][\"bad\"] += 1\n",
    "\n",
    "print(\"Users total: \", len(users_dict))\n",
    "bad_users = []\n",
    "for key, value in users_dict.items():\n",
    "    percentage_good = value[\"good\"]/(value[\"good\"] + value[\"bad\"])\n",
    "    if percentage_good < 0.5:\n",
    "        bad_users.append(key)\n",
    "\n",
    "print(\"Bad users:\", len(bad_users))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "41 из 191 разметчиков на контрольных заданиях показали слишком плохое качество, чтобы учитывать их ответы для расчета метрики."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Отделяем контроль от основы, так как контрольные задания создавались отдельно и не должны учитываться при подсчете метрик. На контрольных заданиях есть `GOLDEN:answer`. Также отсеиваем возможные баги Толоки, когда в строке может не быть задания - `INPUT:question` содержит NaN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "assignments_no_control = assignments[assignments['GOLDEN:answer'].isnull()]\n",
    "assignments_no_control_no_null = assignments_no_control[assignments_no_control['INPUT:question'].notnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посчитаем, сколько было затрачено на получение разметки тестовых данных без учета контрольных заданий, так как они могли проходиться неограниченное количество раз одним и тем же разметчиком."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "взвешенная цена айтема в тесте: 0.031\n",
      "потрачено на разметку теста: 81.312\n",
      "81.312 / 0.031\n"
     ]
    }
   ],
   "source": [
    "def w_sum(df):\n",
    "    idx = df.index.values\n",
    "    vals = df.values\n",
    "    summ = idx * vals\n",
    "    return summ.sum()\n",
    "\n",
    "d1 = assignments_no_control_no_null['ASSIGNMENT:reward'].value_counts(normalize=True)\n",
    "d2 = assignments_no_control_no_null['ASSIGNMENT:reward'].value_counts()\n",
    "print(f'взвешенная цена айтема в тесте: {round(w_sum(d1), 3)}')\n",
    "print(f'потрачено на разметку теста: {round(w_sum(d2), 3)}')\n",
    "print(f'{round(w_sum(d2), 3)} / {round(w_sum(d1), 3)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выделим, сколько составила средняя часовая ставка для разметки тестовой части датасета. Это будет простое среднее из следующих величин: количество заданий, которое разметчк может сделать за час на основе данного задания, помноженное на цену задания."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.359464540236515"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_hour_pay(df):\n",
    "    try:\n",
    "        times = pd.to_datetime(df['ASSIGNMENT:submitted']) - pd.to_datetime(df['ASSIGNMENT:started'])\n",
    "    except Exception as e:\n",
    "        times = []\n",
    "        for i in range(len(assignments_no_control_no_null)):\n",
    "            try:\n",
    "                start = pd.to_datetime(assignments_no_control_no_null['ASSIGNMENT:started'].iloc[i])\n",
    "            except Exception as e:\n",
    "                start = pd.to_datetime(assignments_no_control_no_null['ASSIGNMENT:started'].apply(lambda x: x.split('T')[1]).iloc[i])\n",
    "            try:\n",
    "                end = pd.to_datetime(assignments_no_control_no_null['ASSIGNMENT:submitted'].iloc[i])\n",
    "            except Exception as e:\n",
    "                start = pd.to_datetime(assignments_no_control_no_null['ASSIGNMENT:submitted'].apply(lambda x: x.split('T')[1]).iloc[i])\n",
    "            delta = end - start\n",
    "            times.extend([delta])\n",
    "        times = pd.Series(times)\n",
    "        # times = pd.to_datetime(df['ASSIGNMENT:submitted'].apply(lambda x: x.split('T')[1])) - pd.to_datetime(df['ASSIGNMENT:started'].apply(lambda x: x.split('T')[1]))\n",
    "    sums = 3600 / times.apply(lambda x: x.seconds) * df['ASSIGNMENT:reward']\n",
    "    return sums.mean()\n",
    "\n",
    "get_hour_pay(assignments_no_control_no_null)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Сбор ответов разметчиков и голосование"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Собираем ответы голосования большинством для каждого задания."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "525\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "text_dict = defaultdict(list)\n",
    "\n",
    "for task, op1, op2, op3, op4, user, out in zip(\n",
    "    assignments_no_control_no_null[\"INPUT:question\"], assignments_no_control_no_null[\"INPUT:option_a\"],\n",
    "    assignments_no_control_no_null[\"INPUT:option_b\"], assignments_no_control_no_null[\"INPUT:option_c\"], \n",
    "    assignments_no_control_no_null[\"INPUT:option_d\"],\n",
    "    assignments_no_control_no_null[\"ASSIGNMENT:worker_id\"], assignments_no_control_no_null[\"OUTPUT:answer\"]\n",
    "    ):\n",
    "    if user not in bad_users:\n",
    "        text_dict[(task, op1, op2, op3, op4)].append([\n",
    "                user,\n",
    "                {\"out\": out}\n",
    "        ])\n",
    "\n",
    "print(len(text_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({5: 415, 4: 99, 3: 10, 2: 1})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keys = list(text_dict.keys())\n",
    "Counter([len(text_dict[keys[i]]) for i in range(len(keys))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Есть 110 заданий, где перекрытие меньше 5. Для формирования итоговых лейблов нужно, чтобы было простое большинство разметчиков, проголосовавших за данную опцию. Если большинства нет, то оценка строится, исходя из оценки навыков разметчиков. В таком случае, финальный лейбл будет присвоен по голосу группы с наилучшими навыками. Если по навыкам будет равенство, то решаем по ответам топ-3 по навыкам разметчиков. Если и данный способ дает равенство, то используются оценки навыков разметчиков из EM-алгоритма (реализация GLAD)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_full = {}\n",
    "user2skill = {k:v for k, v in zip(skills['worker_id'], skills['skill_value'])}\n",
    "control_acc = assignments[assignments['GOLDEN:answer'].notna()]\\\n",
    "    .groupby('ASSIGNMENT:worker_id')\\\n",
    "        .apply(lambda x: (np.array(x['OUTPUT:answer']) == np.array(x['GOLDEN:answer'])).mean())\n",
    "user2control = {k:v for k, v in zip(control_acc.index, control_acc.values)}\n",
    "\n",
    "from crowdkit.aggregation.classification.glad import GLAD\n",
    "\n",
    "full = assignments['INPUT:question'] + ' ' + assignments['INPUT:option_a'] + ' ' + assignments['INPUT:option_b'] + ' ' + assignments['INPUT:option_c'] + ' ' + assignments['INPUT:option_d']\n",
    "id2task = dict(enumerate(full))\n",
    "task2id = {k:v for v, k in id2task.items()}\n",
    "id2user = dict(enumerate(assignments['ASSIGNMENT:worker_id']))\n",
    "user2id = {k:v for v, k in id2user.items()}\n",
    "\n",
    "codes = full.map(task2id)\n",
    "res = pd.DataFrame({'task': codes, 'worker': assignments['ASSIGNMENT:worker_id'].map(user2id), 'label': assignments['OUTPUT:answer']})\n",
    "model = GLAD(n_iter=10000, tol=1e-06, m_step_max_iter=1000, m_step_tol=1e-03)\n",
    "model.fit(res)\n",
    "user2alpha = dict(enumerate(model.alphas_))\n",
    "tb = model.alphas_.copy()\n",
    "tb.index = tb.index.map(id2user)\n",
    "user2alpha = {k:v for k, v in zip(tb.index, tb.values)}\n",
    "\n",
    "stats = {\n",
    "    'total_agreement': 0,\n",
    "    'majority': 0,\n",
    "    'skill_based': 0,\n",
    "    'major_based': 0,\n",
    "    'em_based': 0,\n",
    "    'rest': 0,\n",
    "}\n",
    "\n",
    "for i in range(len(keys)):\n",
    "    ans = text_dict[keys[i]]\n",
    "    lst = [[ans[j][0], ans[j][1]['out']] for j in range(len(ans))]\n",
    "    users, votes = list(zip(*lst))\n",
    "    cnt = pd.Series(Counter(votes)).sort_values(ascending=False)\n",
    "\n",
    "    # # total agreement\n",
    "    if len(cnt) == 1:\n",
    "        res = cnt.index[0]\n",
    "        stats['total_agreement'] += 1\n",
    "    # simple majority\n",
    "    elif cnt.iloc[0] > cnt.iloc[1]:\n",
    "        res = cnt.index[0]\n",
    "        stats['majority'] += 1\n",
    "    # (> 1 options) & (1 option == 2 option)\n",
    "    else:\n",
    "        # try overall skill based comparison\n",
    "        vals = list(map(lambda x: user2skill[x], users))\n",
    "        table = pd.DataFrame({'user': users, 'votes': votes, 'skill': vals})\n",
    "        agg = table.groupby('votes').agg(\n",
    "            sum_skill=pd.NamedAgg(column='skill', aggfunc='sum'),\n",
    "            sum_votes=pd.NamedAgg(column='user', aggfunc='count')\n",
    "        ).sort_values(by=['sum_votes', 'sum_skill'], ascending=False)\n",
    "        # check there is a leader by skills\n",
    "        if agg['sum_skill'].iloc[0] > agg['sum_skill'].iloc[1]:\n",
    "            res = agg.index[0]\n",
    "            stats['skill_based'] += 1\n",
    "        else:\n",
    "            # top-3 answers by overall skills\n",
    "            vals = list(map(lambda x: user2skill[x], users))\n",
    "            table = pd.DataFrame({'user': users, 'votes': votes, 'skill': vals})\n",
    "            table = table.sort_values(by='skill', ascending=False)\n",
    "            if len(table) >= 3:\n",
    "                sub = table.iloc[:3]\n",
    "            else:\n",
    "                sub = table\n",
    "            agg = sub.groupby('votes').agg(\n",
    "                sum_skill=pd.NamedAgg(column='skill', aggfunc='sum'),\n",
    "                sum_votes=pd.NamedAgg(column='user', aggfunc='count')\n",
    "            ).sort_values(by=['sum_votes', 'sum_skill'], ascending=False)\n",
    "            if agg['sum_skill'].iloc[0] != agg['sum_skill'].iloc[1]:\n",
    "                res = agg.index[0]\n",
    "                stats['major_based'] += 1\n",
    "            \n",
    "            else:\n",
    "                vals = list(map(lambda x: user2alpha[x], users))\n",
    "                table = pd.DataFrame({'user': users, 'votes': votes, 'skill': vals})\n",
    "                agg = table.groupby('votes').agg(\n",
    "                    sum_skill=pd.NamedAgg(column='skill', aggfunc='sum'),\n",
    "                    sum_votes=pd.NamedAgg(column='user', aggfunc='count')\n",
    "                ).sort_values(by=['sum_votes', 'sum_skill'], ascending=False)\n",
    "                # check there is a leader by skills\n",
    "                if agg['sum_skill'].iloc[0] != agg['sum_skill'].iloc[1]:\n",
    "                    res = agg.index[0]\n",
    "                    stats['em_based'] += 1\n",
    "                else:\n",
    "                    res = agg.index[0]\n",
    "                    stats['rest'] += 1\n",
    "\n",
    "    preds_full[keys[i]] = res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'total_agreement': 356,\n",
       " 'majority': 155,\n",
       " 'skill_based': 11,\n",
       " 'major_based': 2,\n",
       " 'em_based': 1,\n",
       " 'rest': 0}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_full_df = pd.concat([pd.DataFrame(preds_full.keys(), columns=['task', 'op1', 'op2', 'op3', 'op4']), pd.DataFrame(preds_full.values(), columns=['lb'])], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Сопоставление разметки и ground truth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Забираем задания из датасета с правильными ответами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df = pd.read_csv('general_wa.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df = res_df.rename({\n",
    "    'INPUT:question': 'task',\n",
    "    'INPUT:option_a': 'op1',\n",
    "    'INPUT:option_b': 'op2',\n",
    "    'INPUT:option_c': 'op3',\n",
    "    'INPUT:option_d': 'op4',\n",
    "    'GOLDEN:answer': 'lb',\n",
    "}, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "После скачивания с Толоки в текстах рушится форматирование, потому нельзя просто сделать join двух табличек. Нужно убрать все \"лишнее\" форматирование сразу из двух табличек, чтобы остались только тексты, пунктуация и пробелы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_text(text):\n",
    "    text = (text.strip().replace('\\n', ' ').replace('\\t', ' ')\n",
    "            .replace('\\r', ' ').replace('  ', ' ').replace('  ', ' ')\n",
    "            .replace('  ', ' '))\n",
    "    return text\n",
    "\n",
    "res_df['task'] = res_df['task'].apply(format_text)\n",
    "res_df['op1'] = res_df['op1'].apply(format_text)\n",
    "res_df['op2'] = res_df['op2'].apply(format_text)\n",
    "res_df['op3'] = res_df['op3'].apply(format_text)\n",
    "res_df['op4'] = res_df['op4'].apply(format_text)\n",
    "\n",
    "preds_full_df['task'] = preds_full_df['task'].apply(format_text)\n",
    "preds_full_df['op1'] = preds_full_df['op1'].apply(format_text)\n",
    "preds_full_df['op2'] = preds_full_df['op2'].apply(format_text)\n",
    "preds_full_df['op3'] = preds_full_df['op3'].apply(format_text)\n",
    "preds_full_df['op4'] = preds_full_df['op4'].apply(format_text)\n",
    "\n",
    "res_df['full'] = res_df['task'] + ' ' + res_df['op1'] + ' ' + res_df['op2'] + ' ' + res_df['op3'] + ' ' + res_df['op4']\n",
    "preds_full_df['full'] = preds_full_df['task'] + ' ' + preds_full_df['op1'] + ' ' + preds_full_df['op2'] + ' ' + preds_full_df['op3'] + ' ' + preds_full_df['op4']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Делаем left join, чтобы соединить голосование и правильные метки для одних и тех же заданий."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "new = res_df.merge(preds_full_df.drop(['task', 'op1', 'op2', 'op3', 'op4'], axis=1), on='full', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "525"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_valid = new[new['lb_y'].notna()].copy()\n",
    "len(new_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ни одна строка не была утеряна."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lb_x</th>\n",
       "      <th>task</th>\n",
       "      <th>op1</th>\n",
       "      <th>op2</th>\n",
       "      <th>op3</th>\n",
       "      <th>op4</th>\n",
       "      <th>full</th>\n",
       "      <th>lb_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>Человеческое тело получает энергию, необходиму...</td>\n",
       "      <td>пищи</td>\n",
       "      <td>почвы</td>\n",
       "      <td>солнечного света</td>\n",
       "      <td>воды</td>\n",
       "      <td>Человеческое тело получает энергию, необходиму...</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  lb_x                                               task   op1    op2  \\\n",
       "0    A  Человеческое тело получает энергию, необходиму...  пищи  почвы   \n",
       "\n",
       "                op3   op4                                               full  \\\n",
       "0  солнечного света  воды  Человеческое тело получает энергию, необходиму...   \n",
       "\n",
       "  lb_y  \n",
       "0    A  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_valid.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подсчет метрики"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если в правом столбце меток осталось 499 непустых строк, значит, форматирование было подчищено корректно и ничего не потерялось"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем посчитать разные метрики"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9352380952380952"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(new_valid['lb_x'] == new_valid['lb_y']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9352531240689137"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(new_valid['lb_x'], new_valid['lb_y'], average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Accuracy = 0.935`, `F1_macro = 0.935`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
