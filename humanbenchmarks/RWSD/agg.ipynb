{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Аггрегация разметки датасета RWSD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Аггрегация строится по следующей системе:\n",
    "\n",
    "1. Сбор размеченных пулов с Толоки. Возможны варианты:\n",
    "    - только общий пул нужно аггрегировать, тогда забирается только он\n",
    "    - часть данных находится в контрольных заданиях и экзамене, тогда к основному пулу добавляются данные задания\n",
    "2. Фильтрация разметчиков:\n",
    "    - в общем пуле есть некоторое количество заранее размеченных заданий - контрольных\n",
    "    - хорошим считается разметчик, который показывает `accuracy >= 0.5` на данных заданиях\n",
    "    - формируется список \"плохих\" разметчиков\n",
    "3. Аггрегация ответов разметчиков по заданиям:\n",
    "    - форматирование в заданиях может отличаться от изначального из-за выгрузки с Толоки\n",
    "    - учитываются только ответы \"хороших\" разметчиков\n",
    "    - аггрегация по подготовленным пулам - создается массив карточек вида {key: value}, где key - кортеж из всех значимых элементов задания, value - список из кортежей вида (user_id, answer)\n",
    "4. Голосование большинством по каждому заданию:\n",
    "    - минимально необходимое большинство составляет 3 голоса, так как такое большинство валидно для перекрытия 5\n",
    "    - по результату формируется датафрейм с заданиями и ответами\n",
    "5. Подгрузка оригинальных данных с разметкой в виде таблицы с заданиями и ответами\n",
    "6. Соединение таблиц:\n",
    "    - очистка форматирования в таблице с ответами разметчиков и в таблице с правильными ответами\n",
    "    - создание единых столбцов с полным заданием\n",
    "    - соединение таблиц по данному столбцу\n",
    "    - валидация размеров\n",
    "7. Подсчет метрик"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Сбор данных разметки и фильтрация разметчиков"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Всего в разметку попали 260 объектов, включая, как \"старые\" данные (до расширения тестового сета), так и \"новые\" (добавленные в процессе расширения тестового сета)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Виноград прогонялся двумя пулами. В первый пул попали почти все добавленные объекты. Во второй пул попали 4 новых добавленных объектов (но размер второго пула больше из-за контрольных заданий)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "assignments1 = pd.read_csv('assignments_from_pool_41009024__19-12-2023.tsv', sep='\\t')\n",
    "assignments2 = pd.read_csv('assignments_from_pool_41266267__19-12-2023.tsv', sep='\\t')\n",
    "skills = pd.read_csv('workerSkills.csv', sep='|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "assignments = pd.concat([assignments1, assignments2[assignments1.columns]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разметчикам предлагалось на основании имеющихся текст, фраз со словом и с предлогом из данного текста ответить на вопрос, относятся ли обе фразы к одной и той же сущности.\n",
    "\n",
    "Вход: \n",
    "- INPUT:text (пример: `Пршел к Владу и Маше в гости. Она открыла дверь`).\n",
    "- INPUT:word (пример: `Маша`).\n",
    "- INPUT:pronoun (пример: `Она`).\n",
    "\n",
    "Выход:\n",
    "- OUTPUT:result (булеан: `True` или `False`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>INPUT:text</th>\n",
       "      <th>INPUT:word</th>\n",
       "      <th>INPUT:pronoun</th>\n",
       "      <th>OUTPUT:result</th>\n",
       "      <th>GOLDEN:result</th>\n",
       "      <th>HINT:text</th>\n",
       "      <th>HINT:default_language</th>\n",
       "      <th>ASSIGNMENT:link</th>\n",
       "      <th>ASSIGNMENT:task_id</th>\n",
       "      <th>ASSIGNMENT:assignment_id</th>\n",
       "      <th>ASSIGNMENT:task_suite_id</th>\n",
       "      <th>ASSIGNMENT:worker_id</th>\n",
       "      <th>ASSIGNMENT:status</th>\n",
       "      <th>ASSIGNMENT:started</th>\n",
       "      <th>ASSIGNMENT:submitted</th>\n",
       "      <th>ASSIGNMENT:accepted</th>\n",
       "      <th>ASSIGNMENT:reward</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Боб заплатил за обучение Чарльза в университет...</td>\n",
       "      <td>Боб</td>\n",
       "      <td>Он</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://platform.toloka.ai/task/41009024/00027...</td>\n",
       "      <td>000271bf80--64ef36132409351a10c5f66d</td>\n",
       "      <td>000271bf80--64ef38197c475157010635d8</td>\n",
       "      <td>000271bf80--64ef38187c475157010635d2</td>\n",
       "      <td>36d93d4f906f48015a04300bb61d8ff1</td>\n",
       "      <td>APPROVED</td>\n",
       "      <td>2023-08-30T12:37:45</td>\n",
       "      <td>2023-08-30T12:38:29.678</td>\n",
       "      <td>2023-08-30T12:38:29.678</td>\n",
       "      <td>0.019</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          INPUT:text INPUT:word INPUT:pronoun  \\\n",
       "0  Боб заплатил за обучение Чарльза в университет...        Боб            Он   \n",
       "\n",
       "   OUTPUT:result GOLDEN:result  HINT:text  HINT:default_language  \\\n",
       "0           True          True        NaN                    NaN   \n",
       "\n",
       "                                     ASSIGNMENT:link  \\\n",
       "0  https://platform.toloka.ai/task/41009024/00027...   \n",
       "\n",
       "                     ASSIGNMENT:task_id              ASSIGNMENT:assignment_id  \\\n",
       "0  000271bf80--64ef36132409351a10c5f66d  000271bf80--64ef38197c475157010635d8   \n",
       "\n",
       "               ASSIGNMENT:task_suite_id              ASSIGNMENT:worker_id  \\\n",
       "0  000271bf80--64ef38187c475157010635d2  36d93d4f906f48015a04300bb61d8ff1   \n",
       "\n",
       "  ASSIGNMENT:status   ASSIGNMENT:started     ASSIGNMENT:submitted  \\\n",
       "0          APPROVED  2023-08-30T12:37:45  2023-08-30T12:38:29.678   \n",
       "\n",
       "       ASSIGNMENT:accepted  ASSIGNMENT:reward  \n",
       "0  2023-08-30T12:38:29.678              0.019  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assignments.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Фильтруем толокеров, которые дали меньше половины корректных ответов на контрольных заданиях."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Users total:  155\n",
      "Bad users: 5\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "users_dict = defaultdict(lambda: defaultdict(int))\n",
    "\n",
    "for idx, row in assignments.iterrows():\n",
    "    text = row[0]\n",
    "    word = row[1]\n",
    "    pron = row[2]\n",
    "\n",
    "    out = row[3]\n",
    "    \n",
    "    gold = row[4]\n",
    "\n",
    "    user = row[11]\n",
    "\n",
    "    if str(user) != \"nan\" and str(gold) != \"nan\":\n",
    "        if out == int(gold):\n",
    "            users_dict[user][\"good\"] += 1\n",
    "        else:\n",
    "            users_dict[user][\"bad\"] += 1\n",
    "\n",
    "print(\"Users total: \", len(users_dict))\n",
    "bad_users = []\n",
    "for key, value in users_dict.items():\n",
    "    percentage_good = value[\"good\"]/(value[\"good\"] + value[\"bad\"])\n",
    "    if percentage_good < 0.5:\n",
    "        bad_users.append(key)\n",
    "\n",
    "print(\"Bad users:\", len(bad_users))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5 из 155 разметчиков на контрольных заданиях показали слишком плохое качество, чтобы учитывать их ответы для расчета метрики."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь нужно оставить только основной пул. Контрольные задания брались из трейна Винограда, потому их нужно убрать. На контрольных заданиях есть `GOLDEN:result`. Также отсеиваем возможные баги Толоки, когда в строке может не быть задания - `INPUT:text` содержит NaN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "assignments_no_control = assignments[assignments['GOLDEN:result'].isnull()]\n",
    "assignments_no_control_no_null = assignments_no_control[assignments_no_control['INPUT:text'].notnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посчитаем, сколько было затрачено на получение разметки тестовых данных без учета контрольных заданий, так как они могли проходиться неограниченное количество раз одним и тем же разметчиком."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "взвешенная цена айтема в тесте: 0.021\n",
      "потрачено на разметку теста: 27.046\n",
      "27.046 / 0.021\n"
     ]
    }
   ],
   "source": [
    "def w_sum(df):\n",
    "    idx = df.index.values\n",
    "    vals = df.values\n",
    "    summ = idx * vals\n",
    "    return summ.sum()\n",
    "\n",
    "d1 = assignments_no_control_no_null['ASSIGNMENT:reward'].value_counts(normalize=True)\n",
    "d2 = assignments_no_control_no_null['ASSIGNMENT:reward'].value_counts()\n",
    "print(f'взвешенная цена айтема в тесте: {round(w_sum(d1), 3)}')\n",
    "print(f'потрачено на разметку теста: {round(w_sum(d2), 3)}')\n",
    "print(f'{round(w_sum(d2), 3)} / {round(w_sum(d1), 3)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выделим, сколько составила средняя часовая ставка для разметки тестовой части датасета. Это будет простое среднее из следующих величин: количество заданий, которое разметчк может сделать за час на основе данного задания, помноженное на цену задания."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.4836675506254484"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_hour_pay(df):\n",
    "    try:\n",
    "        times = pd.to_datetime(df['ASSIGNMENT:submitted']) - pd.to_datetime(df['ASSIGNMENT:started'])\n",
    "    except Exception as e:\n",
    "        times = []\n",
    "        for i in range(len(df)):\n",
    "            try:\n",
    "                start = pd.to_datetime(df['ASSIGNMENT:started'].iloc[i])\n",
    "            except Exception as e:\n",
    "                start = pd.to_datetime(df['ASSIGNMENT:started'].apply(lambda x: x.split('T')[1]).iloc[i])\n",
    "            try:\n",
    "                end = pd.to_datetime(df['ASSIGNMENT:submitted'].iloc[i])\n",
    "            except Exception as e:\n",
    "                start = pd.to_datetime(df['ASSIGNMENT:submitted'].apply(lambda x: x.split('T')[1]).iloc[i])\n",
    "            delta = end - start\n",
    "            times.extend([delta])\n",
    "        times = pd.Series(times)\n",
    "        # times = pd.to_datetime(df['ASSIGNMENT:submitted'].apply(lambda x: x.split('T')[1])) - pd.to_datetime(df['ASSIGNMENT:started'].apply(lambda x: x.split('T')[1]))\n",
    "    sums = 3600 / times.apply(lambda x: x.seconds) * df['ASSIGNMENT:reward']\n",
    "    return sums.mean()\n",
    "\n",
    "get_hour_pay(assignments_no_control_no_null)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Сбор ответов разметчиков и голосование"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Собираем ответы голосования большинством для каждого задания."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "260\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "text_dict = defaultdict(list)\n",
    "\n",
    "for text, word, pron, user, out in zip(\n",
    "    assignments_no_control_no_null[\"INPUT:text\"], assignments_no_control_no_null[\"INPUT:word\"],\n",
    "    assignments_no_control_no_null[\"INPUT:pronoun\"], assignments_no_control_no_null[\"ASSIGNMENT:worker_id\"], \n",
    "    assignments_no_control_no_null[\"OUTPUT:result\"]\n",
    "    ):\n",
    "    if user not in bad_users:\n",
    "        text_dict[(text, word, pron)].append([\n",
    "                user,\n",
    "                {\"out\": out}\n",
    "        ])\n",
    "\n",
    "print(len(text_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({5: 250, 4: 10})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keys = list(text_dict.keys())\n",
    "Counter([len(text_dict[keys[i]]) for i in range(len(keys))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Есть 10 заданий с перектрытием 4. Для формирования итоговых лейблов нужно, чтобы было простое большинство разметчиков, проголосовавших за данную опцию. Если большинства нет, то оценка строится, исходя из оценки навыков разметчиков. В таком случае, финальный лейбл будет присвоен по голосу группы с наилучшими навыками."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_full = {}\n",
    "user2skill = {k:v for k, v in zip(skills['worker_id'], skills['skill_value'])}\n",
    "control_acc = assignments[assignments['GOLDEN:result'].notna()]\\\n",
    "    .groupby('ASSIGNMENT:worker_id')\\\n",
    "        .apply(lambda x: (np.array(x['OUTPUT:result']) == np.array(x['GOLDEN:result'])).mean())\n",
    "user2control = {k:v for k, v in zip(control_acc.index, control_acc.values)}\n",
    "\n",
    "from crowdkit.aggregation.classification.glad import GLAD\n",
    "\n",
    "full = assignments['INPUT:text'] + ' ' + assignments['INPUT:word'] + ' ' + assignments['INPUT:pronoun']\n",
    "id2task = dict(enumerate(full))\n",
    "task2id = {k:v for v, k in id2task.items()}\n",
    "id2user = dict(enumerate(assignments['ASSIGNMENT:worker_id']))\n",
    "user2id = {k:v for v, k in id2user.items()}\n",
    "\n",
    "codes = full.map(task2id)\n",
    "res = pd.DataFrame({'task': codes, 'worker': assignments['ASSIGNMENT:worker_id'].map(user2id), 'label': assignments['OUTPUT:result'].astype(int)})\n",
    "model = GLAD(n_iter=10000, tol=1e-06, m_step_max_iter=1000, m_step_tol=1e-03)\n",
    "model.fit(res)\n",
    "user2alpha = dict(enumerate(model.alphas_))\n",
    "tb = model.alphas_.copy()\n",
    "tb.index = tb.index.map(id2user)\n",
    "user2alpha = {k:v for k, v in zip(tb.index, tb.values)}\n",
    "\n",
    "stats = {\n",
    "    'total_agreement': 0,\n",
    "    'majority': 0,\n",
    "    'skill_based': 0,\n",
    "    'major_based': 0,\n",
    "    'em_based': 0,\n",
    "    'rest': 0,\n",
    "}\n",
    "\n",
    "for i in range(len(keys)):\n",
    "    ans = text_dict[keys[i]]\n",
    "    lst = [[ans[j][0], ans[j][1]['out']] for j in range(len(ans))]\n",
    "    users, votes = list(zip(*lst))\n",
    "    cnt = pd.Series(Counter(votes)).sort_values(ascending=False)\n",
    "\n",
    "    # # total agreement\n",
    "    if len(cnt) == 1:\n",
    "        res = cnt.index[0]\n",
    "        stats['total_agreement'] += 1\n",
    "    # simple majority\n",
    "    elif cnt.iloc[0] > cnt.iloc[1]:\n",
    "        res = cnt.index[0]\n",
    "        stats['majority'] += 1\n",
    "    # (> 1 options) & (1 option == 2 option)\n",
    "    else:\n",
    "        # try overall skill based comparison\n",
    "        vals = list(map(lambda x: user2skill[x], users))\n",
    "        table = pd.DataFrame({'user': users, 'votes': votes, 'skill': vals})\n",
    "        agg = table.groupby('votes').agg(\n",
    "            sum_skill=pd.NamedAgg(column='skill', aggfunc='sum'),\n",
    "            sum_votes=pd.NamedAgg(column='user', aggfunc='count')\n",
    "        ).sort_values(by=['sum_votes', 'sum_skill'], ascending=False)\n",
    "        # check there is a leader by skills\n",
    "        if agg['sum_skill'].iloc[0] > agg['sum_skill'].iloc[1]:\n",
    "            res = agg.index[0]\n",
    "            stats['skill_based'] += 1\n",
    "        else:\n",
    "            # top-3 answers by overall skills\n",
    "            vals = list(map(lambda x: user2skill[x], users))\n",
    "            table = pd.DataFrame({'user': users, 'votes': votes, 'skill': vals})\n",
    "            table = table.sort_values(by='skill', ascending=False)\n",
    "            if len(table) >= 3:\n",
    "                sub = table.iloc[:3]\n",
    "            else:\n",
    "                sub = table\n",
    "            agg = sub.groupby('votes').agg(\n",
    "                sum_skill=pd.NamedAgg(column='skill', aggfunc='sum'),\n",
    "                sum_votes=pd.NamedAgg(column='user', aggfunc='count')\n",
    "            ).sort_values(by=['sum_votes', 'sum_skill'], ascending=False)\n",
    "            if agg['sum_skill'].iloc[0] != agg['sum_skill'].iloc[1]:\n",
    "                res = agg.index[0]\n",
    "                stats['major_based'] += 1\n",
    "            \n",
    "            else:\n",
    "                vals = list(map(lambda x: user2alpha[x], users))\n",
    "                table = pd.DataFrame({'user': users, 'votes': votes, 'skill': vals})\n",
    "                agg = table.groupby('votes').agg(\n",
    "                    sum_skill=pd.NamedAgg(column='skill', aggfunc='sum'),\n",
    "                    sum_votes=pd.NamedAgg(column='user', aggfunc='count')\n",
    "                ).sort_values(by=['sum_votes', 'sum_skill'], ascending=False)\n",
    "                # check there is a leader by skills\n",
    "                if agg['sum_skill'].iloc[0] != agg['sum_skill'].iloc[1]:\n",
    "                    res = agg.index[0]\n",
    "                    stats['em_based'] += 1\n",
    "                else:\n",
    "                    res = agg.index[0]\n",
    "                    stats['rest'] += 1\n",
    "\n",
    "    preds_full[keys[i]] = res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'total_agreement': 137,\n",
       " 'majority': 122,\n",
       " 'skill_based': 1,\n",
       " 'major_based': 0,\n",
       " 'em_based': 0,\n",
       " 'rest': 0}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Только в 1 объекте согласованность не была достигнута. Убираем его."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_full_df = pd.concat([pd.DataFrame(preds_full.keys(), columns=['text', 'span1', 'span2']), pd.DataFrame(preds_full.values(), columns=['lb'])], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Сопоставление разметки и ground truth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Забираем задания из датасета с правильными метками."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df = pd.read_csv('winograd.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "После скачивания с Толоки в текстах рушится форматирование, потому нельзя просто сделать join двух табличек. Нужно убрать все \"лишнее\" форматирование сразу из двух табличек, чтобы остались только тексты, пунктуация и пробелы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_text(text):\n",
    "    text = (text.strip().replace('\\n', ' ').replace('\\t', ' ')\n",
    "            .replace('\\r', ' ').replace('  ', ' ').replace('  ', ' ')\n",
    "            .replace('  ', ' '))\n",
    "    return text\n",
    "\n",
    "res_df['text'] = res_df['text'].apply(format_text)\n",
    "res_df['span1'] = res_df['span1'].apply(format_text)\n",
    "res_df['span2'] = res_df['span2'].apply(format_text)\n",
    "\n",
    "preds_full_df['text'] = preds_full_df['text'].apply(format_text)\n",
    "preds_full_df['span1'] = preds_full_df['span1'].apply(format_text)\n",
    "preds_full_df['span2'] = preds_full_df['span2'].apply(format_text)\n",
    "\n",
    "res_df['full'] = res_df['text'] + ' ' + res_df['span1'] + ' ' + res_df['span2']\n",
    "preds_full_df['full'] = preds_full_df['text'] + ' ' + preds_full_df['span1'] + ' ' + preds_full_df['span2']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Делаем left join, чтобы соединить голосование и правильные метки для одних и тех же заданий."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "new = res_df.merge(preds_full_df.drop(['text', 'span1', 'span2'], axis=1), on='full', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "260"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_valid = new[new['lb_y'].notna()].copy()\n",
    "len(new_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>span1</th>\n",
       "      <th>span2</th>\n",
       "      <th>lb_x</th>\n",
       "      <th>full</th>\n",
       "      <th>lb_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Мод и Дора видели, как через прерию несутся по...</td>\n",
       "      <td>Мод и Дора</td>\n",
       "      <td>они появились</td>\n",
       "      <td>False</td>\n",
       "      <td>Мод и Дора видели, как через прерию несутся по...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Мод и Дора видели, как через прерию несутся по...</td>\n",
       "      <td>поезда</td>\n",
       "      <td>они появились</td>\n",
       "      <td>True</td>\n",
       "      <td>Мод и Дора видели, как через прерию несутся по...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Мод и Дора видели, как через прерию несутся по...</td>\n",
       "      <td>клубы</td>\n",
       "      <td>они появились</td>\n",
       "      <td>False</td>\n",
       "      <td>Мод и Дора видели, как через прерию несутся по...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Мод и Дора видели, как через прерию несутся по...</td>\n",
       "      <td>Ревущие звуки</td>\n",
       "      <td>они появились</td>\n",
       "      <td>False</td>\n",
       "      <td>Мод и Дора видели, как через прерию несутся по...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Мод и Дора видели, как через прерию несутся по...</td>\n",
       "      <td>свистки</td>\n",
       "      <td>они появились</td>\n",
       "      <td>False</td>\n",
       "      <td>Мод и Дора видели, как через прерию несутся по...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text          span1  \\\n",
       "0  Мод и Дора видели, как через прерию несутся по...     Мод и Дора   \n",
       "1  Мод и Дора видели, как через прерию несутся по...         поезда   \n",
       "2  Мод и Дора видели, как через прерию несутся по...          клубы   \n",
       "3  Мод и Дора видели, как через прерию несутся по...  Ревущие звуки   \n",
       "4  Мод и Дора видели, как через прерию несутся по...        свистки   \n",
       "\n",
       "           span2   lb_x                                               full  \\\n",
       "0  они появились  False  Мод и Дора видели, как через прерию несутся по...   \n",
       "1  они появились   True  Мод и Дора видели, как через прерию несутся по...   \n",
       "2  они появились  False  Мод и Дора видели, как через прерию несутся по...   \n",
       "3  они появились  False  Мод и Дора видели, как через прерию несутся по...   \n",
       "4  они появились  False  Мод и Дора видели, как через прерию несутся по...   \n",
       "\n",
       "    lb_y  \n",
       "0  False  \n",
       "1   True  \n",
       "2  False  \n",
       "3  False  \n",
       "4  False  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_valid.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подсчет метрики"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если в правом столбце меток осталось 259 непустых строк, значит, форматирование было подчищено корректно и ничего не потерялось."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_valid['lb_y'] = new_valid['lb_y'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8346153846153846"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(new_valid['lb_x'] == new_valid['lb_y']).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Accuracy = 0.835`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
